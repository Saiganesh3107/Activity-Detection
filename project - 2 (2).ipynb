{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YOLO(\n",
       "  (model): ClassificationModel(\n",
       "    (model): Sequential(\n",
       "      (0): Conv(\n",
       "        (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv(\n",
       "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (2): C3k2(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): Conv(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (4): C3k2(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): Conv(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (6): C3k2(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): C3k(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv3): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (m): Sequential(\n",
       "              (0): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (1): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): Conv(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (8): C3k2(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): C3k(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv3): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (m): Sequential(\n",
       "              (0): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (1): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): C2PSA(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): Sequential(\n",
       "          (0): PSABlock(\n",
       "            (attn): Attention(\n",
       "              (qkv): Conv(\n",
       "                (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (proj): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (pe): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "            (ffn): Sequential(\n",
       "              (0): Conv(\n",
       "                (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): Classify(\n",
       "        (conv): Conv(\n",
       "          (conv): Conv2d(256, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (pool): AdaptiveAvgPool2d(output_size=1)\n",
       "        (drop): Dropout(p=0.0, inplace=True)\n",
       "        (linear): Linear(in_features=1280, out_features=15, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = YOLO(r\"E:\\ML-Project\\nano_best_1.pt\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[137, 155, 167],\n",
       "        [137, 155, 167],\n",
       "        [137, 155, 167],\n",
       "        ...,\n",
       "        [ 93, 124, 159],\n",
       "        [ 91, 124, 160],\n",
       "        [ 94, 128, 165]],\n",
       "\n",
       "       [[137, 155, 167],\n",
       "        [137, 155, 167],\n",
       "        [137, 155, 167],\n",
       "        ...,\n",
       "        [ 93, 124, 159],\n",
       "        [ 92, 126, 161],\n",
       "        [ 94, 128, 165]],\n",
       "\n",
       "       [[137, 155, 167],\n",
       "        [137, 155, 167],\n",
       "        [137, 155, 167],\n",
       "        ...,\n",
       "        [ 93, 126, 159],\n",
       "        [ 92, 126, 160],\n",
       "        [ 94, 128, 163]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 60,  72,  89],\n",
       "        [ 60,  72,  89],\n",
       "        [ 57,  69,  86],\n",
       "        ...,\n",
       "        [ 33,  53,  89],\n",
       "        [ 38,  56,  90],\n",
       "        [ 42,  59,  90]],\n",
       "\n",
       "       [[ 61,  73,  90],\n",
       "        [ 59,  71,  89],\n",
       "        [ 57,  69,  86],\n",
       "        ...,\n",
       "        [ 34,  53,  88],\n",
       "        [ 38,  55,  88],\n",
       "        [ 42,  59,  90]],\n",
       "\n",
       "       [[ 61,  73,  90],\n",
       "        [ 59,  71,  88],\n",
       "        [ 56,  68,  85],\n",
       "        ...,\n",
       "        [ 34,  53,  87],\n",
       "        [ 39,  57,  88],\n",
       "        [ 43,  59,  89]]], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread(r\"E:\\ML-Project\\eating.png\")\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x480 laughing 0.99, calling 0.00, clapping 0.00, hugging 0.00, eating 0.00, 39.0ms\n",
      "Speed: 6.8ms preprocess, 39.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 480)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: None\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'calling', 1: 'clapping', 2: 'cycling', 3: 'dancing', 4: 'drinking', 5: 'eating', 6: 'fighting', 7: 'hugging', 8: 'laughing', 9: 'listening_to_music', 10: 'running', 11: 'sitting', 12: 'sleeping', 13: 'texting', 14: 'using_laptop'}\n",
       " obb: None\n",
       " orig_img: array([[[137, 155, 167],\n",
       "         [137, 155, 167],\n",
       "         [137, 155, 167],\n",
       "         ...,\n",
       "         [ 93, 124, 159],\n",
       "         [ 91, 124, 160],\n",
       "         [ 94, 128, 165]],\n",
       " \n",
       "        [[137, 155, 167],\n",
       "         [137, 155, 167],\n",
       "         [137, 155, 167],\n",
       "         ...,\n",
       "         [ 93, 124, 159],\n",
       "         [ 92, 126, 161],\n",
       "         [ 94, 128, 165]],\n",
       " \n",
       "        [[137, 155, 167],\n",
       "         [137, 155, 167],\n",
       "         [137, 155, 167],\n",
       "         ...,\n",
       "         [ 93, 126, 159],\n",
       "         [ 92, 126, 160],\n",
       "         [ 94, 128, 163]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 60,  72,  89],\n",
       "         [ 60,  72,  89],\n",
       "         [ 57,  69,  86],\n",
       "         ...,\n",
       "         [ 33,  53,  89],\n",
       "         [ 38,  56,  90],\n",
       "         [ 42,  59,  90]],\n",
       " \n",
       "        [[ 61,  73,  90],\n",
       "         [ 59,  71,  89],\n",
       "         [ 57,  69,  86],\n",
       "         ...,\n",
       "         [ 34,  53,  88],\n",
       "         [ 38,  55,  88],\n",
       "         [ 42,  59,  90]],\n",
       " \n",
       "        [[ 61,  73,  90],\n",
       "         [ 59,  71,  88],\n",
       "         [ 56,  68,  85],\n",
       "         ...,\n",
       "         [ 34,  53,  87],\n",
       "         [ 39,  57,  88],\n",
       "         [ 43,  59,  89]]], dtype=uint8)\n",
       " orig_shape: (700, 577)\n",
       " path: 'image0.jpg'\n",
       " probs: ultralytics.engine.results.Probs object\n",
       " save_dir: 'runs\\\\classify\\\\predict'\n",
       " speed: {'preprocess': 6.758689880371094, 'inference': 38.98262977600098, 'postprocess': 0.0}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = model.predict(img)\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ultralytics.engine.results.Probs object with attributes:\n",
       "\n",
       "data: tensor([4.1997e-03, 2.9895e-03, 1.4537e-06, 8.8548e-04, 7.2644e-04, 1.8173e-03, 5.4514e-04, 2.2921e-03, 9.8503e-01, 8.4641e-04, 4.0694e-06, 8.6515e-05, 3.6343e-04, 2.0388e-04, 7.8628e-06])\n",
       "orig_shape: None\n",
       "shape: torch.Size([15])\n",
       "top1: 8\n",
       "top1conf: tensor(0.9850)\n",
       "top5: [8, 0, 1, 7, 5]\n",
       "top5conf: tensor([0.9850, 0.0042, 0.0030, 0.0023, 0.0018])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k[0].probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'calling',\n",
       " 1: 'clapping',\n",
       " 2: 'cycling',\n",
       " 3: 'dancing',\n",
       " 4: 'drinking',\n",
       " 5: 'eating',\n",
       " 6: 'fighting',\n",
       " 7: 'hugging',\n",
       " 8: 'laughing',\n",
       " 9: 'listening_to_music',\n",
       " 10: 'running',\n",
       " 11: 'sitting',\n",
       " 12: 'sleeping',\n",
       " 13: 'texting',\n",
       " 14: 'using_laptop'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = k[0].names\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'laughing'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_predicted = classes[k[0].probs.top5[0]]\n",
    "class_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 persons, 4 wine glasss, 98.3ms\n",
      "Speed: 0.0ms preprocess, 98.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4 wine glasss, 180.1ms\n",
      "Speed: 3.1ms preprocess, 180.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 4 wine glasss, 1 chair, 75.5ms\n",
      "Speed: 4.0ms preprocess, 75.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 1 bottle, 3 wine glasss, 1 chair, 109.4ms\n",
      "Speed: 4.0ms preprocess, 109.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 7 wine glasss, 88.7ms\n",
      "Speed: 2.9ms preprocess, 88.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 4 wine glasss, 102.7ms\n",
      "Speed: 15.8ms preprocess, 102.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 2 wine glasss, 116.2ms\n",
      "Speed: 7.3ms preprocess, 116.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 4 wine glasss, 1 chair, 169.2ms\n",
      "Speed: 2.5ms preprocess, 169.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 3 wine glasss, 101.4ms\n",
      "Speed: 2.3ms preprocess, 101.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 4 wine glasss, 86.4ms\n",
      "Speed: 3.2ms preprocess, 86.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 3 wine glasss, 87.1ms\n",
      "Speed: 3.4ms preprocess, 87.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 4 wine glasss, 90.1ms\n",
      "Speed: 8.0ms preprocess, 90.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 6 wine glasss, 91.7ms\n",
      "Speed: 5.8ms preprocess, 91.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 6 wine glasss, 83.8ms\n",
      "Speed: 3.3ms preprocess, 83.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 5 wine glasss, 83.9ms\n",
      "Speed: 3.1ms preprocess, 83.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 4 wine glasss, 90.1ms\n",
      "Speed: 4.3ms preprocess, 90.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 3 wine glasss, 70.6ms\n",
      "Speed: 7.7ms preprocess, 70.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 4 wine glasss, 98.1ms\n",
      "Speed: 1.8ms preprocess, 98.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 101.8ms\n",
      "Speed: 11.1ms preprocess, 101.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 wine glass, 122.1ms\n",
      "Speed: 3.2ms preprocess, 122.1ms inference, 9.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 wine glass, 99.0ms\n",
      "Speed: 5.4ms preprocess, 99.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 116.7ms\n",
      "Speed: 5.3ms preprocess, 116.7ms inference, 11.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 wine glass, 159.2ms\n",
      "Speed: 0.0ms preprocess, 159.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 94.2ms\n",
      "Speed: 4.6ms preprocess, 94.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 241.0ms\n",
      "Speed: 4.4ms preprocess, 241.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 1 cup, 204.8ms\n",
      "Speed: 12.9ms preprocess, 204.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 1 cup, 415.5ms\n",
      "Speed: 6.4ms preprocess, 415.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 7 persons, 146.4ms\n",
      "Speed: 8.3ms preprocess, 146.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 wine glass, 283.4ms\n",
      "Speed: 13.6ms preprocess, 283.4ms inference, 9.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 8 persons, 185.2ms\n",
      "Speed: 2.7ms preprocess, 185.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 5 persons, 1 wine glass, 1 chair, 302.8ms\n",
      "Speed: 3.9ms preprocess, 302.8ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 6 persons, 1 frisbee, 1 wine glass, 367.3ms\n",
      "Speed: 21.5ms preprocess, 367.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import face_recognition\n",
    "\n",
    "# Load YOLO model for person detection\n",
    "model = YOLO('yolov8n.pt')  # Model trained with \"person\" class (e.g., COCO dataset)\n",
    "\n",
    "# Load the reference image of the specific person\n",
    "reference_image = face_recognition.load_image_file(r\"E:\\ML-Project\\eating.png\")\n",
    "reference_encoding = face_recognition.face_encodings(reference_image)[0]  # Get face encoding for the reference image\n",
    "\n",
    "# Open video capture\n",
    "cap = cv2.VideoCapture(r\"E:\\ML-Project\\eating.mp4\")\n",
    "\n",
    "# Set video resolution (optional)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "\n",
    "while cap.isOpened():\n",
    "    success, frame = cap.read()  # Read a frame from the video\n",
    "    if not success:\n",
    "        print(\"Failed to read frame or end of video.\")\n",
    "        break\n",
    "\n",
    "    # Perform person detection on the frame\n",
    "    results = model(frame)  # Run YOLO model on the frame\n",
    "\n",
    "    # Iterate over detected objects in the results\n",
    "    for box in results[0].boxes:\n",
    "        # Get the predicted class and confidence score\n",
    "        class_id = int(box.cls[0])  # Class ID of the detected object\n",
    "        confidence = float(box.conf[0])  # Confidence score of the detection\n",
    "\n",
    "        # Only process detections with the \"person\" class\n",
    "        if class_id == 0:  # Assuming \"person\" class ID is 0 in COCO-trained YOLO models\n",
    "            # Get bounding box coordinates\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])  # top-left and bottom-right corners\n",
    "            person_roi = frame[y1:y2, x1:x2]\n",
    "\n",
    "            # Convert the detected region to RGB format (required by face_recognition)\n",
    "            person_roi_rgb = cv2.cvtColor(person_roi, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Detect face in the ROI\n",
    "            face_encodings = face_recognition.face_encodings(person_roi_rgb)\n",
    "            if face_encodings:\n",
    "                # Compare detected face with the reference face\n",
    "                match = face_recognition.compare_faces([reference_encoding], face_encodings[0], tolerance=0.6)\n",
    "                \n",
    "                if match[0]:  # If there's a match\n",
    "                    # Draw a rectangle around the matched person\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                    \n",
    "                    # Display class name and confidence on the video frame\n",
    "                    cv2.putText(frame, f\"Matched Person {confidence:.2f} {class_predicted}\", (x1, y1 - 10),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 2, cv2.LINE_AA)\n",
    "    \n",
    "    # Show the frame with matched person detections only\n",
    "    cv2.imshow(\"YOLO - Matched Person Detection\", frame)\n",
    "\n",
    "    # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
